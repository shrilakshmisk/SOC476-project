{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "\n",
    "# Define file paths\n",
    "fp1 = \"./states and ut/1_LASI_W1_HH_roster.sav\"\n",
    "fp2 = \"./states and ut/2_LASI_W1_Household_v4.sav\"\n",
    "fp3 = \"./states and ut/3_LASI_W1_Individual_v4.sav\"\n",
    "fp4 = \"./states and ut/4_LASI_W1_Biomarker.sav\"\n",
    "fp5 = \"./states and ut/5_LASI_W1_CV_memberfile.sav\"\n",
    "fp6 = \"./states and ut/6_LASI_W1_CV_deathmemberfile.sav\"\n",
    "fp7 = \"./states and ut/LASI_W1_Community_data_AllstatesUTs_v4.sav\"\n",
    "\n",
    "# Read files\n",
    "# df1, meta1 = pyreadstat.read_sav(fp1)\n",
    "# df2, meta2 = pyreadstat.read_sav(fp2)\n",
    "# df4, meta4 = pyreadstat.read_sav(fp4)\n",
    "# df5, meta5 = pyreadstat.read_sav(fp5)\n",
    "# df6, meta6 = pyreadstat.read_sav(fp6)\n",
    "# df7, meta7 = pyreadstat.read_sav(fp7)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create column mapping (code -> label) for each file\n",
    "cl1 = meta1.column_labels\n",
    "cl2 = meta2.column_labels\n",
    "# cl3 = meta3.column_labels\n",
    "cl4 = meta4.column_labels\n",
    "cl5 = meta5.column_labels\n",
    "cl6 = meta6.column_labels\n",
    "# cl7 = meta7.column_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! CSV saved as: fp1_states.csv\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.sav' with the path to your .sav file\n",
    "sav_file_path = fp1\n",
    "csv_file_path = 'fp1_states.csv'\n",
    "\n",
    "# Read the .sav file\n",
    "df, meta = pyreadstat.read_sav(sav_file_path)\n",
    "df.columns = meta.column_labels\n",
    "# Convert DataFrame to CSV\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Conversion complete! CSV saved as: {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Residence</th>\n",
       "      <th>Birth District</th>\n",
       "      <th>Migration Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Current Residence Birth District  Migration Status\n",
       "0               1.0            nan                 1\n",
       "1               1.0            nan                 1\n",
       "2               1.0            1.0                 0\n",
       "3               1.0            nan                 1\n",
       "4               1.0            1.0                 0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "\n",
    "# Read the SPSS file (fp3.sav) and its metadata\n",
    "\n",
    "\n",
    "# Function to get the variable name given a column label (case-insensitive)\n",
    "def get_varname_by_label(meta, target_label):\n",
    "    target_label = target_label.strip().lower()\n",
    "    for var, label in meta.column_names_to_labels.items():\n",
    "        if label is not None and label.strip().lower() == target_label:\n",
    "            return var\n",
    "    return None\n",
    "\n",
    "# Get variable names based on column labels\n",
    "col_name_residence = get_varname_by_label(meta, \"Place of residence\")\n",
    "if col_name_residence is None:\n",
    "    raise ValueError(\"Column label 'Place of residence' not found in fp3.sav metadata.\")\n",
    "\n",
    "col_name_birth = get_varname_by_label(meta, \"Place of birth-village/town\")\n",
    "if col_name_birth is None:\n",
    "    raise ValueError(\"Column label 'Place of birth-district' not found in fp3.sav metadata.\")\n",
    "\n",
    "# Extract the relevant columns\n",
    "current_residence = df[col_name_residence]\n",
    "birth_district = df[col_name_birth]\n",
    "\n",
    "# Clean the data: convert to strings, strip whitespace, and convert to lowercase\n",
    "current_residence_clean = current_residence.astype(str).str.strip().str.lower()\n",
    "birth_district_clean = birth_district.astype(str).str.strip().str.lower()\n",
    "\n",
    "# Compute migration status:\n",
    "# 1 indicates that current residence is different from birth district (migrant)\n",
    "# 0 indicates that they are the same (non-migrant)\n",
    "migration_status = (current_residence_clean != birth_district_clean).astype(int)\n",
    "\n",
    "# Create a DataFrame with three columns: current residence, birth district, and migration status\n",
    "df_migration = pd.DataFrame({\n",
    "    \"Current Residence\": current_residence_clean,\n",
    "    \"Birth District\": birth_district_clean,\n",
    "    \"Migration Status\": migration_status\n",
    "})\n",
    "\n",
    "# The final DataFrame 'df_migration' now contains the three desired columns.\n",
    "df_migration.head()  # This line is optional; it will display the first few rows in a notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of migration status:\n",
      "1    43693\n",
      "0    29703\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of 1's and 0's in the migration status Series\n",
    "counts = migration_status.value_counts()\n",
    "print(\"Counts of migration status:\")\n",
    "print(counts)\n",
    "\n",
    "# Alternatively, if you need to use the numpy array:\n",
    "# unique, counts_array = np.unique(migration_status_array, return_counts=True)\n",
    "# print(\"Unique values and counts (using numpy):\")\n",
    "# print(dict(zip(unique, counts_array)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp3, meta_fp3 = pyreadstat.read_sav(fp3, encoding=\"latin1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Birth District'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Birth District'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 43\u001b[0m\n\u001b[0;32m     36\u001b[0m birth_district_clean \u001b[38;5;241m=\u001b[39m birth_district\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Compute migration status:\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# 1 indicates that current residence is different from birth district (migrant)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 0 indicates that they are the same (non-migrant)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# migration_status = (current_residence_clean != birth_district_clean).astype(int)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Convert 'nan' string to actual NaN\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[43mdf_filtered\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBirth District\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m], np\u001b[38;5;241m.\u001b[39mnan, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Compute migration status:\u001b[39;00m\n\u001b[0;32m     46\u001b[0m df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMigration Status\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[0;32m     47\u001b[0m     df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBirth District\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;241m0\u001b[39m,  \u001b[38;5;66;03m# If birth district is NaN, mark as non-migrant (0)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     (df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent Residence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m df_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBirth District\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)  \u001b[38;5;66;03m# Otherwise, compare values\u001b[39;00m\n\u001b[0;32m     49\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py:3760\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3760\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3762\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Birth District'"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "\n",
    "# Read the SPSS file (fp3.sav) and its metadata\n",
    "\n",
    "# Function to get the variable name given a column label (case-insensitive)\n",
    "def get_varname_by_label(meta, target_label):\n",
    "    target_label = target_label.strip().lower()\n",
    "    for var, label in meta.column_names_to_labels.items():\n",
    "        if label is not None and label.strip().lower() == target_label:\n",
    "            return var\n",
    "    return None\n",
    "\n",
    "# Get variable names based on column labels\n",
    "col_name_residence = get_varname_by_label(meta_fp3, \"Place of residence\")\n",
    "if col_name_residence is None:\n",
    "    raise ValueError(\"Column label 'Place of residence' not found in fp3.sav metadata.\")\n",
    "\n",
    "col_name_birth = get_varname_by_label(meta_fp3, \"Place of birth-village/town\")\n",
    "if col_name_birth is None:\n",
    "    raise ValueError(\"Column label 'Place of birth-district' not found in fp3.sav metadata.\")\n",
    "\n",
    "col_name_age = get_varname_by_label(meta_fp3, \"Age at last birthday\")\n",
    "if col_name_age is None:\n",
    "    raise ValueError(\"Column label 'Age at last birthday' not found in fp3.sav metadata.\")\n",
    "\n",
    "# Filter the dataset to include only individuals aged 60 or above\n",
    "df_filtered = df_fp3[df_fp3[col_name_age] >= 60]\n",
    "\n",
    "# Extract the relevant columns from the filtered data\n",
    "current_residence = df_filtered[col_name_residence]\n",
    "birth_district = df_filtered[col_name_birth]\n",
    "\n",
    "# Clean the data: convert to strings, strip whitespace, and convert to lowercase\n",
    "current_residence_clean = current_residence.astype(str).str.strip().str.lower()\n",
    "birth_district_clean = birth_district.astype(str).str.strip().str.lower()\n",
    "\n",
    "# Compute migration status:\n",
    "# 1 indicates that current residence is different from birth district (migrant)\n",
    "# 0 indicates that they are the same (non-migrant)\n",
    "# migration_status = (current_residence_clean != birth_district_clean).astype(int)\n",
    "\n",
    "# Create a DataFrame with three columns: current residence, birth district, and migration status\n",
    "df_migration = pd.DataFrame({\n",
    "    \"Current Residence\": current_residence_clean,\n",
    "    \"Birth District\": birth_district_clean,\n",
    "    \"Migration Status\": migration_status\n",
    "})\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "print(df_migration.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import ace_tools as tools  # For displaying dataframe\n",
    "\n",
    "\n",
    "# Function to get the variable name given a column label (case-insensitive)\n",
    "def get_varname_by_label(meta, target_label):\n",
    "    target_label = target_label.strip().lower()\n",
    "    for var, label in meta.column_names_to_labels.items():\n",
    "        if label is not None and label.strip().lower() == target_label:\n",
    "            return var\n",
    "    return None\n",
    "\n",
    "# Get variable names based on column labels\n",
    "col_name_residence = get_varname_by_label(meta_fp3, \"Place of residence\")\n",
    "if col_name_residence is None:\n",
    "    raise ValueError(\"Column label 'Place of residence' not found in fp3.sav metadata.\")\n",
    "\n",
    "col_name_birth = get_varname_by_label(meta_fp3, \"Place of birth-village/town\")\n",
    "if col_name_birth is None:\n",
    "    raise ValueError(\"Column label 'Place of birth-village/town' not found in fp3.sav metadata.\")\n",
    "\n",
    "col_name_age = get_varname_by_label(meta_fp3, \"Age at last birthday\")\n",
    "if col_name_age is None:\n",
    "    raise ValueError(\"Column label 'Age at last birthday' not found in fp3.sav metadata.\")\n",
    "\n",
    "# Filter the dataset to include only individuals aged 60 or above\n",
    "df_filtered = df_fp3[df_fp3[col_name_age] >= 60].copy()\n",
    "\n",
    "# Extract the relevant columns\n",
    "df_filtered[\"Current Residence\"] = df_filtered[col_name_residence].astype(str).str.strip().str.lower()\n",
    "df_filtered[\"Birth District\"] = df_filtered[col_name_birth].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Convert 'nan' strings and empty strings to actual NaN\n",
    "df_filtered[\"Birth District\"].replace([\"nan\", \"\"], np.nan, inplace=True)\n",
    "\n",
    "# Compute migration status:\n",
    "df_filtered[\"Migration Status\"] = np.where(\n",
    "    df_filtered[\"Birth District\"].isna(), 0,  # If birth district is NaN, mark as non-migrant (0)\n",
    "    (df_filtered[\"Current Residence\"] != df_filtered[\"Birth District\"]).astype(int)  # Otherwise, compare values\n",
    ")\n",
    "\n",
    "# Create a DataFrame with three columns\n",
    "df_migration = df_filtered[[\"Current Residence\", \"Birth District\", \"Migration Status\"]]\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "# tools.display_dataframe_to_user(name=\"Migration Status Data\", dataframe=df_migration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of migration status:\n",
      "Migration Status\n",
      "0    26907\n",
      "1     4995\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df_migration[\"Migration Status\"].value_counts()\n",
    "print(\"Counts of migration status:\")\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   migration_2  migration_3\n",
      "0            0            6\n",
      "1            0            6\n",
      "2            0            5\n",
      "3            0            6\n",
      "4            0            6\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the SPSS file (fp3.sav) and its metadata\n",
    "# df_fp3, meta_fp3 = pyreadstat.read_sav(\"fp3.sav\")\n",
    "\n",
    "# Function to get the variable name given a column label (case-insensitive)\n",
    "def get_varname_by_label(meta, target_label):\n",
    "    target_label = target_label.strip().lower()\n",
    "    for var, label in meta.column_names_to_labels.items():\n",
    "        if label is not None and label.strip().lower() == target_label:\n",
    "            return var\n",
    "    return None\n",
    "\n",
    "# Get variable name for \"Since how many years living continuously in this area\"\n",
    "col_name_years = get_varname_by_label(meta_fp3, \"Since how many years living continuously in this area\")\n",
    "if col_name_years is None:\n",
    "    raise ValueError(\"Column label 'Since how many years living continuously in this area' not found in fp3.sav metadata.\")\n",
    "\n",
    "# Convert the column to numeric (handling errors)\n",
    "years_living = pd.to_numeric(df_fp3[col_name_years], errors='coerce')\n",
    "\n",
    "# Create a new DataFrame for migration_2 and migration_3\n",
    "df_migration_2_3 = pd.DataFrame()\n",
    "\n",
    "# Create migration_2: 0 if years >= 20, else 1\n",
    "df_migration_2_3[\"migration_2\"] = np.where(years_living >= 25, 0, 1)\n",
    "\n",
    "# Define bins and labels for migration_3\n",
    "bins = [-np.inf, 2, 5, 10, 20, 40, np.inf]\n",
    "labels = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Use pd.cut, and fill NaN values with a default category (e.g., 0 for unknown)\n",
    "df_migration_2_3[\"migration_3\"] = pd.cut(years_living, bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Convert migration_3 to integer, replacing NaN with 0 (or any default category you prefer)\n",
    "df_migration_2_3[\"migration_3\"] = df_migration_2_3[\"migration_3\"].cat.add_categories(0).fillna(0).astype(int)\n",
    "\n",
    "# Display first few rows of the new DataFrame\n",
    "print(df_migration_2_3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of migration status:\n",
      "migration_2\n",
      "0    60862\n",
      "1    12534\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df_migration_2_3[\"migration_2\"].value_counts()\n",
    "print(\"Counts of migration status:\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
